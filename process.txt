This is a project that will create an accounting and logging system for my trading business.  
Previously, I utilized MS Excel to log trades and conduct simple accounting.  
However, Excel has limitations and is not very scalable.  
The goal is to automate this process to the fullest extent possible and have all of the trade logs 
and accounting information in a relational database that is accessible, scalable, searchable, flexible, 
and limits manual entry.  This project will start very simple by utilizing python and sqlite3.  
The project will grow over time to incorporate more sophisticated databases such as postgreSQL 
and web applications (e.g. Flask and Django). 


Phase 0: The goal of phase 0 is to evaluate the underlying data that you will need to extract, transform, and load (ETL). 
The .csv files from your broker are the tools and data sources you will need to evaluate. 
1. Examine and assess the data structure and formats since this will guide the design of the relational database. 
2. Write out the process. 


Phase I: The goal of phase I is to create the basic structure of the database and the first three tables. 
Python and sqlite3 / postgreSQL are the two primary tools for this phase. 
1. Create a git repository called "trade accounting and log system" and the associated files.
2. Create a visual layout of the ETL process.  
3. Use python to create the database, tables, datatypes, etc. 
4. The database is in development mode during this stage.
5. Create the database_dev_mode.py and the logs_metrics_app_dev_mode.py file.
6. Create the first three tables: activity_log, brokers, and time_log.
7. Test input data into the these first three tables using the logs_metrics_app_dev_mode.py. 


Phase II: The goal of phase II is to build the initial Extract, Transform, and Load (ETL) process. 
1. Sqlite3 and / or postgreSQL are the primary tools for this phase. 
2. The database_dev_mode.py file is still in development during this stage.
3. Create the fx_log table. 
4. Insert dummy data and test the foreign key relationship in the fx_log table.
5. Create the python file fx.py that will extract, clean, and import data from the fx broker .csv file. 
6. The python fx.py file will load the cleaned data into the logs_metrics_app_dev_mode.py.
7. The logs_metrics_app_dev_mode.py file should successfully load the .csv data into the database.
8. Dowload .csv files (at least six different months) and test  the app to ensure it returns the proper results.  
9. Upload the monthly results to the logs_metrics_app_dev_mode.py file then into the database.
10. Run queries on the uploaded monthly data.  The gain / loss should match the broker statements.


Phase III: The goal of phase III is to continue to build the Extract, Transform, and Load (ETL) process.
1. Sqlite3 and / or postgreSQL are the primary tools for this phase.
2. The database_dev_mode.py file is still in development during this stage.
3. Create the options_log table.
4. Insert dummy data and test the foreign key relationships in the options_log table.
5. Create the python files td.py and ib.py that will extract, clean, and import data from the fx broker .csv file.
6. The python td.py ib.py files will load the cleaned data into the logs_metrics_app_dev_mode.py.
7. The logs_metrics_app_dev_mode.py file should successfully load the .csv data into the database.


Phase IV: place holder - create the final tables


Phase V: The goal of phase V is to perform successful tests of the entire ETL process.
1. Perform unit tests on all python files to ensure everything works properly.
