commit 0bb0fda3f24eff1d34e82ad5f5e2d10e81af8052
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Apr 11 13:52:26 2022 -0400

    add functions and successfully exported fx records into the database
    for commissions, interest credt / debit, and broker credits

commit 8bbfe2128fe7e97faef4bdf5577c4e805533b51a
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Apr 11 13:50:26 2022 -0400

    modified the fx_broker_credit_add_records() function to add decimals
    to the transaction ids that I created to avoid UNIQUE CONSTRAINT
    ERRORS

commit 6a0f40a1a318800b2145861df3cb8a5a66dc36f0
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Apr 11 13:49:04 2022 -0400

    added tables and functions to export records to the database for commissions,
    interest credit / debits, and broker credits

commit 7b186131beb751bf16d38562327afcc23f82d12d
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Apr 11 10:02:50 2022 -0400

    updated the jpeg file for the database layout

commit 4973778a259361edd1251652444c6dd289d856f4
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Apr 10 06:25:11 2022 -0400

    updated the bugs file

commit dbb882dca8281b2adc2369f280bf56c0ce36c512
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Apr 10 06:10:16 2022 -0400

    modify the duplicate debit interest, credit interest, and commission
    transaction ids by adding a decimal value to these numbers; the values
    are not ideal becuase I was unable to get them in the correct order
    along with the correct order fo the transaction ids but it will
    have to do for now; next and the new tables to the DB.

commit 6a4d209145ed5c28bf990bbcbe0b231e692ea384
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Apr 10 04:43:34 2022 -0400

    I was unable to resolve the issue of the getting  dupicate transaction ids
    in order with a decimal that denotes the number of duplicates; this problem
     will need to be resolved later; the next solution is not ideal but to
    just use a simple counter for the decimal values to avoid the UNIQUE
    CONSTRAINT ERRORS

commit bb1a0dce1e0ff10a2385567bb2fabed38484756d
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Apr 9 12:59:46 2022 -0400

    I am facing the same problem trying to get the modified duplicates
    in the same order as the broker data; no solution so far

commit 257eadb9e9f8fc44578ef648fee28dd0fee2e7c4
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Apr 7 19:20:12 2022 -0400

    add code to sections 773 - 883 and it needs more work; trying to get the
    modified transaction ids in the correct order of the data; keep working
    on this section

commit 1b98a786939888e5d664d727068f216453138809
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Apr 5 14:53:13 2022 -0400

    added section 744 - 774 within the fx_int_credit_add_record() function;
    found a solution that modifies the duplicate transaction ids by adding
    decimals to the ids; next I need to get the modified transaction ids
    into the int_credit list along with the other variables then I will
    have a complete list of records for the interest credit items

commit 53be9be0577da8044c8a987549152f38026bd660
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Apr 3 19:40:03 2022 -0400

    updated sections 813 - 873 the fx_broker_credit_add_records() function;
    added a transaction id for each broker_credit; next do the same for
    fx_int_credit_add_records() and fx_int_debit_add_records functions

commit fdc4d35180be1c2577f8ce974db966f85dbb5400
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Apr 3 19:38:53 2022 -0400

    updated the layout of the database; added columns for transaction ids
    to the commission, interest income, interest, fees, and broker credit
    tables

commit 4470856e59d1fa5dd66c525bb6b14b2ed6d13ed7
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Apr 3 19:37:57 2022 -0400

    updated the log file

commit cfc85640f956fed8517700eaefbd04154983c263
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Apr 2 18:26:35 2022 -0400

    completed sections 599 - 873 which are four functions to extract the
    commissions, interest debit, interest credit, and broker credits and
    gets the dates into the proper format for the relational database;
    the functions all work correctly; the next step is to create the
    tables and write the code to import the data into the db.

commit 783ca21e869ea072685d4576cb3ee321cd3700e9
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Apr 1 19:44:30 2022 -0400

    completed the code for the fx_comm_add_records function in section
    597 - 691 that captures the the commission costs and formats the dates;
    next test this section again then do the same for the debit  interest

commit 439dbd0da0f98fa66a7dd7dc6f093610827b00a8
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Mar 31 21:26:22 2022 -0400

    added code to sections 596 - 622 to account for different date formats
    for commission transactions in the broker data

commit 4aee30f5e1c58b6038380c812f1f5afd028d6072
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Mar 27 13:50:51 2022 -0400

    started the process to extract the commissions and interest from the
    broker data; created fx_int_debit_add_records() and fx_comm_add_records()
    functions in sections 600-664 and began to format the data; next I need
    to format the dates to account for various date formatting; use the previous
    sections 133-260 as a model

commit bce0f3a4b6b2d55e44ac6076241ded802fba4ca0
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Mar 27 13:50:34 2022 -0400

    updated the log file

commit 7bf02211afc2da98f8acacb753b367f2829815e9
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 26 14:25:21 2022 -0400

    created a separate logs_metrics_app_dev_mode_test.py file for testing
    The export_corrected_duplicate_id() is incomplete; I have been unsuccessful.
    export_corrected_duplicate_id() function provides a partial solution only so
    continue to work on it in testing mode

commit 1bd41940a75a13a3e5b9b8503ba28b79ad135f68
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 26 14:21:45 2022 -0400

    created a file for bugs and items that need to corrections

commit 79c4cc99973c1e815abef0dbd005d16ff3f29507
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Mar 22 11:58:56 2022 -0400

    continued work on the export_corrected_duplicate_id() function section
    214-265; continued work on sections 214-265 that searches for duplicates
    of corrected duplicate transaction ids in the fx_log table to avoid
    UNIQUE CONSTRAINS; I believe I have successfully got the correct code
    without getting any traceback errors for lists out of range;
    next I nneed to thoroughly test this section

commit 86658be4702e67f9334e16b695628651b9785f84
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Mar 22 11:58:33 2022 -0400

    updated the log file

commit ade4f22054f16aac83e7760d693c59d852959959
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 19 13:42:32 2022 -0400

    continued work on the export_corrected_duplicate_id() function section 238 - 282;
    there are bugs in section 238-282 because the code is getting the list
    out of range error; and the the output is not always consistent;
    keep working on this section

commit 55ab2853a37901929f5d0a92301cd35b3eb41e10
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 19 13:42:16 2022 -0400

    updated the log file

commit 793341b5cea1dd7b75c5986736c6e5606dd5ba9b
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Mar 15 10:42:03 2022 -0400

    continued work on the export_corrected_duplicate_id() function;
    identified the source of the problem where the code did not recognize
    duplicated rows that would generate a UNIQUE CONSTRAINT ERROR; the error
    was in the for loops and the difference in lengths between the rows in the
    fx_log table and the items in the duplicates list; modified sections 219-256
    to account for different lenths; sections 259-278 will also require modifications;
    continue work on both sections and test them

commit 3969de3fa9e8c49d3635994b81a5505118a32dcf
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Mar 15 10:41:28 2022 -0400

    updated the log file

commit 58bf7696494a41c3c2243b9bd3db2a37e95cb8f5
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Mar 14 10:28:59 2022 -0400

    continued work on the export_corrected_duplicate_id() function;
    worked on sections 205 - 267 and I am at the 90% solution; there
    is still one bug that needs to be fixed; this section of code correctly
    identifies and exports corrected dupicate transaction ids while avoiding
    a UNIQUE CONSTRAINT ERROR but it only works when the transaction ids
    are grouped and exported together in consecutive order; if the duplicates
    are in randmoized order the code does not generate the correct output;
    next I need to fix this bug

commit 6ddabe404f416bb2d3c4be67a2dfa3656c0e440f
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Mar 14 10:28:36 2022 -0400

    updated the log file

commit 651de146ec5411492a80ef1a01db260350ae90a4
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Mar 13 16:31:45 2022 -0400

    continued to work on the export_corrected_duplicate_id() function;
    workd on section 219-245; this section needs further work as I am
    getting UNIQUE CONSTRAINT ERRORS;

commit cc0b97bd5ac11b023613d39a3ae5e9ae2c948616
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Mar 13 16:31:18 2022 -0400

    updated the log file

commit 28037a9ada06e3ea45eeb340063541d1b926f62b
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 12 14:40:20 2022 -0500

    continued work on the export_fx_log_records function;
    added code in sections 222 - 241 to get the function to avoid UNIQUE
    CONTRAINT ERRORS when  corrected duplicates are placed into the fx_log
    table; the code now correctly identifies any potential duplicates;
    next I need to cast the corrected_dupliates into tuples and export
    them into the fx_log table if those rows are not already present in
    the fx_log table

commit a20426bb4f0b8a8640766cafc2f49ec717196996
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 12 14:39:06 2022 -0500

    updated the log file

commit 1da58c0c3ac7356d358d34024c5b2658649c687c
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Mar 6 11:06:14 2022 -0500

    updated the log file

commit 6a74fcb97b6fb140e7f7cb235e2cfafc545650a4
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Mar 6 11:02:44 2022 -0500

    continued worked on the export_corrected_duplicate_id() function
    sections 188-220; built loops and true / false test to test for
    duplicates in the fx_log table and the dupliates list; need to test
    when the duplicates are either at the top, middle, or bottom to enusure
    the alogo identifies the duplicates regardless of position;

commit 982b6cefa08f2529911904ff96a816e52b83dab9
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 5 12:02:43 2022 -0500

    continued work on the export_corrected_duplicate_id() function;
    I need to find a solution to loop over all the rows in the fx_log table
    and compare if the duplicates are in fx_log table; contine work on this

commit 0a2b155cc9cf1259e85627d6b597ec6defd5bb89
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Mar 5 12:01:42 2022 -0500

    updated the log file

commit a388fc6f31cb393ee2d2e1226b8b7f778fbc4801
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Feb 27 13:06:57 2022 -0500

    corrected an error in the export_fx_log_records() function;
    the export_corrected_duplicate_id() function will need further work;
    the datatypes are tuples and not subscriptable when using for loops
    to compare with existing records in the fx_log table;

commit 13737c12deb89b16a329d7d2b295cb711464b9c6
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Feb 26 13:39:40 2022 -0500

    continued work on the export_corrected_duplicate_id function;
    successfully modified the export_corrected_duplicate_id to correct the
    duplicate close / open ids in the broker data, exported the data, and
    filtered any rows to avoid a UNIQUE CONSTRAINT error; I added the
    itertools module with the zip_longest function to loop over two lists
    to filter duplicate rows and thereby avoiding UNIQUE CONSTRAINT ERRORS;
    there is one remaining item to test on the export_corrected_duplicate_id
    function; ensure the zip_longest function works on the uneven rows;
    so next time import more rows into the fx_log table then retest the function

commit c04885c81fecd7da60cdd69591d27b4d9840c824
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Feb 26 13:39:24 2022 -0500

    updated the log file

commit d3cf57f3958a74143f31f0b13f97513a6ce37125
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Feb 24 13:46:15 2022 -0500

    updated the log_file

commit 7c605816e4b7dc0dba858dc51a2772afceb17963
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Feb 24 13:40:38 2022 -0500

    there are still bugs with the export_corrected_duplicate_id function
    in sections 130 - 160; I will need to relook at the prevous section
    from 98 - 128 that formed the corrected_dupliacte_lst;

commit 9966f4402a61bcd6a15730997ed49cba6213db12
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Feb 24 11:24:37 2022 -0500

    updated the log_file

commit c5b6e641ffebd169067c82687fca6f1199e97355
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Feb 24 11:22:38 2022 -0500

    upated section 157-171 that contains the export_corrected_duplicate()
    function; the function successfully exported the corrected edge cases
    where there are duplicate close / open transaction ids in the broker
    data; next continue to test the function

commit b1b4a6b8a6caf201e6a1df297bbd3a15d42409e3
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Feb 21 11:22:59 2022 -0500

    modified the function that corrects the edge cases where the broker
    data has duplicate close / open ids; modified the actual number to
    add a decimal and counter .01 .02 to distinguish the dupllicate ids
    while retaining the original transaction ids; started writing the code
    to export the data into the fx_log table;

commit abce3b07248ae8055d7cb3da42614990f8288bdc
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Feb 21 11:22:34 2022 -0500

    updated log file

commit 0f1f2998b06757a2ef93f54ed18431312502e8ee
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Feb 21 10:44:39 2022 -0500

    create an additional function as part of the process to to correct
    the edge cases where the broker data has duplicate close / open ids;
    successfully tested the functions on a modified .csv file that contains
    intentional errors; corrected errors and exported the rows into
    fx_log table

commit 87d8f312752fa14b6156c3f295ad4791ced0ca66
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Feb 21 10:44:09 2022 -0500

    updated the log file

commit 41e5d8227b035b34e9e5bdd249cb97c2ec632480
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Feb 20 12:08:27 2022 -0500

    added functions to identify and remove duplicate rows with duplicate
    close or open ids and place them into separate lists; next I need
    to create a new function to correct the duplicate ids

commit 940a7d53a64efcee1e1a29826f102b38936fb8dd
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Feb 18 17:16:59 2022 -0500

    updated the log file

commit 6989ccde363704be55a0b4c815e70155d1bc2e4b
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Feb 18 17:15:08 2022 -0500

    created a function to identify the edge cases in the broker data;
    the function identifies duplicate close and open transaction ids;
    continue work on the function that will correct and modify the
    duplicate and export the corrected row into the fx_log table

commit 2bcf47c6b4d8a6a5f90bee8a822e3d88940e1baf
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Feb 15 19:53:25 2022 -0500

    added logging to the process.txt file

commit 8cb5ced62e63d194fa622fcc88d299e2c29f0623
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Feb 13 11:32:10 2022 -0500

    updated the log file

commit 871445bbb04de32cfed248f06ecbe4bc5643c51b
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Feb 13 11:27:17 2022 -0500

    continued tessing the function in logs_metrics_app_dev_mode.py and
    discovered an edge case in the broker data where there are duplicate
    transaction close_ids that will cause a UNIQUE CONSTRAINT ERROR;
    I will need to make modifications likely by adding a new function
    to account for edge cases in the data such as this one

commit 8d4b7ac79f19e4229e5e376ecc756341583c1282
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Feb 12 14:13:54 2022 -0500

    successfully tested the export_matched_record function in the
    logs_metrics_app_dev_mode.py file on all .csv files;
    successfully tested the export_unmatched_records and
    export_matched_record functions in the logs_metrics_app_dev_mode.py files;
    modified the logs_metrics_app_dev_mode.py file  to add a export_fx_log_records
    function that will check for UNIQUE CONSTRAINT ERRORS before exporting the
    fx_log into the fx_log table;

commit e46b2e7f04eacf4790f8ad146e652284ab95729e
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Feb 6 12:52:03 2022 -0500

    updated the log file

commit cfb4164610d663cf1b2bde1280a5a31005db2234
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Feb 6 12:49:17 2022 -0500

    continued work on the export_matched_rows function to fix a bug;
    successfully fixed the bug; next time test the function on all
    .csv files to enusre I get the correct output

commit 3bfb08d6701b80be604def11c6edd1ba8db49c31
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Feb 5 22:27:56 2022 -0500

    modified the function that exports matched rows to the fx_log table;
    next just test the function on all .csv files

commit 1430f975d4a4e185254d293800c26772dd6a3120
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Feb 5 12:24:13 2022 -0500

    added functions to the the code for clarity but there is a bug to
    fix in the for loops

commit ca9a9eec44ab7cfc92851f80da09b6a0a9d3137b
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 30 10:37:02 2022 -0500

    updated the process.txt file to add a section for moving the log
    files of the project into a sqlite3 database

commit cf51c47bd841028e45e9cd9f1e5b9c48a190a2b7
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 30 10:31:30 2022 -0500

    successfully added the function to test for potential UNIQUE CONSTRAINT
    violations in the fx_unmatched table before those matched rows are
    exported to the fx_log table;  next I need to test the function
    to ensure all output is correct

commit a4d831d83e7448c1f669cc20bfcaa3b5366aa1c8
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 30 10:25:17 2022 -0500

    successfully added the function to test for potential UNIQUE CONSTRAINT
    violations in the fx_unmatched table before those matched rows are
    exported to the fx_log table;  next I need to test the function
    to ensure all output is correct

commit 4b729e47345b9d79f6e433cb5b7e315ebfb79abc
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 29 14:26:17 2022 -0500

    successfully matched entry and exit transactions in the fx_unmatched table;
    succesfully exported the matched entry and exit transaction from
    fx_unmatched table into the fx_log; added a function to check and
    for remove duplicate rows in the fx_unmatched table and fx_log table;
    next task is to continue work on the function

commit 86d2d1adc419dfb8ccc1e9d5f339c5fd93e85943
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Jan 25 16:00:19 2022 -0500

    created a query to for fx_unmatched table; started the process
    to find a method query, match the open_ids to the close_id, and
    replace insert the entry_date

commit d3aa9282032d5a1b53d3ce192b3eb2e34f71c85d
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 23 15:04:51 2022 -0500

    successfully imported unmatched records to the database;
    added a function in the fx_dev_mode.py to move the unmatched transactions
    from the .csv file into logs_metrics_app_dev_mode.py; created a function
    in  logs_metrics_app_dev_mode.py to move the unmatched transactions
    into the fx_unmatched table in database; next ready to query and modify
    the fx_unmatched table

commit 66d75327be49e30b8289d71823da4a184d314923
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 22 13:31:47 2022 -0500

    made more modifications to the code to properly format the dates
    for the unmatched records; successfully completed all of the
    formatting; succesfully tested the modifications on multiple .csv
    files and the code reutnred the correct results; next task is to
    develop the functions that will send  the formatted data to the
     log_metrics_dev_mode.py app

commit ed4cfc3894c9dc5fc84ace560e02698dc43fc8bd
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Jan 18 14:47:33 2022 -0500

    added a section of code to extract and format with unmatched
    transaction close_ids and open_ids; successfully extracted and
    formatted the unmatched recotds; next this is ready for testing
    on multiple .csv files

commit 3ef8f1f9af7357707ef1330f6e16383c4945e455
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Jan 18 13:39:51 2022 -0500

    added in a section of the code to capture rows with unmatched transactions

commit 1755321af2bb6efbabdb3383051a4b0ea8a50c43
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Jan 17 12:46:01 2022 -0500

    began the process to identify, extract, and export the unmatched
    transactions from the fx data; added a table fx_unmatched to the
    database; next work on the fx_dev_mode.py to extract the rows
    with unmatched only open_ids and export it into the
    logs_metrics_app_dev_mode.py app

commit ffdc5351190e2e4d6668f9e150e3741f577fd4d7
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Jan 17 10:36:38 2022 -0500

    sucessfully exported the data from fx_dev_mode.py into the
    logs_metrics_app_dev_mode.py app and into the database;
    the next thing to do is account for unmatched recrods and
    to match them

commit 3401419dc72f90382974f6b5b927001084e72288
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 16 13:00:09 2022 -0500

    successfully tested  the code in fx_dev_mode.py that returns
    the correct data and added a couple of lines to fx_dev_mode.py
    to add the broker_id; the code works; the next task is to
    integrate fx_dev_mode.py functions into logs_metrics_app_dev_mode.py
    that will pull the rows into the database

commit f8ac7109b0debdaa31b48f865f0f4b273b36c399
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 15 13:15:44 2022 -0500

    added some notes for the next tasks to be completed

commit dd504d13a25d9d5f8c00fa025be10511b5932452
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 15 12:48:48 2022 -0500

    succesfully got all of the necessary data into a list with proper formats
    next, do the testing on multiple .csv files to ensure the output is correct

commit 6b9e6aff47e3a8193b42404fd1ec3704cb99d8ed
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 15 11:57:52 2022 -0500

    fixed an error with the ordering of the transaction open ids;
    all rows open and close dates are properly matched;
    dates and times are are properly formatted;
    next, get the remaining items into the finalized list then test

commit 9161211621daa3bd29d36728538d82bb3ab61fbd
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Jan 14 17:47:13 2022 -0500

    continued data formatting and began to construct the final list
    of that will be used to import into the database; the dates have
    all been tested on one year of data and all formats correct;
    however, there the order of the dates are not properly matched to
    the closing transaction ids so this needs to be fixed next time.

commit 33b26ea24ae0e6bda49389fd19d5ef9dba1cc55f
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 9 13:19:02 2022 -0500

    successfully cleaned the formatting of the first two columns with the
    entry and exit dates; next test the process with more data from the broker
    test at one full year month by month to ensure the program captures
    missing data and formats the dates correctly

commit be055659b5c59148635240faef727bcf5ae2441c
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 9 10:44:17 2022 -0500

    continued formatting the data in the fx.py file successfully
    got the date format correct in column 1; next fix column 2

commit a6c4479a873f24adf2548cabd4c8f12dac96b8b0
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 8 13:15:29 2022 -0500

    continued work on data formatting; working on the dates in the list
    the dates are a mess from the .csv file so it requires a bit of work

commit 4cc2f91a4969b45373033c0d52b59e036efc09c8
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 8 11:01:44 2022 -0500

    continued work on the fx_dev_mode.py app; successfully extracted
    the necessary data into lists where I can now begin to clean the
    data

commit fde919306e1af4364cf5a0dc68aa4323bb311b07
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Jan 7 14:26:37 2022 -0500

    created the fx.py file to extract, clean, and load the data from
    a .csv file; made progress on extracting; created sections to alert
    the user if there is missing data; worked on inserting dates into
    a list of extracted rows and this is what needs to be completed next

commit 6c095ebb789623eb10374bb04467288a6a19152d
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Jan 6 14:30:30 2022 -0500

    created the fx_log table; successfully tested the foreign_key
    successfully queried the fx_log table with conditionals using
    dummy data; next build the fx_log.py file that will extract,
    clean, and load the data into the logs_metrics_app_dev_mode.py file

commit 7f54f157be10305aed44031a78590faaabaf2748
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Jan 3 11:23:01 2022 -0500

    made a minor modification to the db schema tables
    completed testing of the time_log table to include foreign keys
    and the date format; next create the fx_log table and start the
    ETL process

commit 2917fbaedf632832647b48da5bc2d1f07cd952dc
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Jan 2 12:57:40 2022 -0500

    contined test the foreign key relationships in the time_log table
    removed the AUTOINCREMENT from schema in the brokers and
    activity_tables based on sqlit3 documentation
    tests for foreign keys, LEFT JOIN ON, conditional WHERE OR clausses
    and LIKE case insensitivity were successful
    next input dummy data using the correct YYYY-MM-DD HH:MM format
    and test the data

commit 2d4cd895e5aed75965fe8e07615c2d6df12acc2f
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Jan 1 20:17:51 2022 -0500

    continued testing of the foreign key relationships in the time_log
    table; successfully created the SQL statements to return the correct
    resuls; next time continue testing the foreign keys with conditionals

commit bbe38f1ab258c57f8bbca8117137641789066753
Author: Rashawn <arctitan78@gmail.com>
Date:   Thu Dec 30 16:35:02 2021 -0500

    mostly worked on querying the time_log table
    I had some trouble with getting the proper output from the
    foreign key relationships; it returns the numbers but not the
    broker / activity column names; need to figure this out

commit cefcac2ab9494770e922755b6faa87c6554f6807
Author: Rashawn <arctitan78@gmail.com>
Date:   Wed Dec 29 16:51:16 2021 -0500

    had issues with a UNIQUE CONSTRAINT error
    successfully identified and solved the issue
    next, continue to test uploading dummy data into the time_log table
    next, test the foreign key relationships to return the correct data

commit 2a258edc5b8d33ea048cf1ea67d514411dc425e3
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 28 16:49:56 2021 -0500

    primarily worked on the time_log table;
    created the table and the functions to input data into the
    time_log; the next step is to test adding and deleting data
    then test the foreign key relationships

commit 6badcd0ce7360d6ef163e99877a44a85c02d64f2
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Dec 26 13:43:07 2021 -0500

    updated the log_file

commit 72ed0b8a6734dfbbed4e22c910d039ac04fcab30
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Dec 26 13:40:54 2021 -0500

    created the firt three tables in the transactions.db database and
    tested inputing data from the python files into the brokers and
    activity log tables; the brokers and activity_log tables are set
    the next step is test inputting data into the time_log table and
    test the primary key associations

commit 6bc7c9a1cf802bcef88388195c72e37e02224bf9
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Dec 26 10:34:10 2021 -0500

    wrote the starter code to form the transaction.db database
    created the first three tables activity_log, brokers, time_log
    modified the transactions_db_diagram to replace "foreign_key"
    with "primary_key" in the time_log table

commit 1f296ed9caeceb572f2dd721d7934f703a176567
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 25 12:06:22 2021 -0500

    created the database_dev_mode.py file
    updated the process.txt file

commit 788f71b7002f54860f4e25c90ec9aba95fd14f45
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 25 12:02:11 2021 -0500

    accidentally added a file that should not be there

commit 6a2098035ff5f5f845f312ead5ce83c6ff5d66e5
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 25 11:53:56 2021 -0500

    added the ex_app_dev_mode.py file

commit 308a0ef77c88d63a1980a35ef65469a879c250e9
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 25 11:03:23 2021 -0500

    made a few minor edits to the transactions.db diagram

commit 54fc85f57606a171a4c083f661b57c7c448642c6
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Dec 24 14:08:52 2021 -0500

    updated the log_file

commit d887ab00c0510afd7ad945f5363352602a2f58e6
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Dec 24 14:07:45 2021 -0500

    finalized the transaction.db diagram
    The basic layout is basically complete
    Time to start coding!!!

commit b02f4a8c06d559fed92155e1e58474dec62041da
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Dec 24 11:54:51 2021 -0500

    updated the log_file

commit 566ffe1d3badcdfa64c6118fff7de14de3ef08d8
Author: Rashawn <arctitan78@gmail.com>
Date:   Fri Dec 24 11:51:21 2021 -0500

    continued to build the transactions database diagram
    there is one final table diagram to complete
    also modifiied the the notes_self_generated_data.txt file to note
    that I will need two separate databases: transactions.db and
    strategy_performance.db

commit 239f373a108912b39bf9af789d64446a8b956eed
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Dec 19 16:28:07 2021 -0500

    updated the log_file

commit 545a2a4cd2b35bb5da3cbae88f84df2a155ba12d
Author: Rashawn <arctitan78@gmail.com>
Date:   Sun Dec 19 16:26:31 2021 -0500

    continued work on the diagram of the tables within the transactions
    database; added multiple tables

commit f4cc591fedd5eded9ea6e12d93f6c7cfd741062a
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 18 12:36:00 2021 -0500

    created a log_file to upload based on git log

commit 10f801dc11c22f5bc6925503e4f7a48fe896be24
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 18 12:12:44 2021 -0500

    completed the basic etl diagram
    started the diagram of the tabels in the transactions database
    created diagram layouts of the following tables:
    time_log, brokers, orders_filled, and activity_log

commit 93d4449519b4bb8d893bd384a3c377eedab24e30
Author: Rashawn <arctitan78@gmail.com>
Date:   Sat Dec 18 09:57:54 2021 -0500

    modified the notes_broker_data.txt file to include a link for editing
    PDFs to grab the data needed

commit d4957b05a7768c07625858f961a49b35150131bf
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 14 13:12:26 2021 -0500

    created the initial ETL diagram flowchart

commit 839ddf858d1525e2739e6000834199b77bb0be79
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 14 09:39:41 2021 -0500

    removed some files

commit 7563657686d1351e38c2561cc5f9843ec1e4becc
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 14 09:37:21 2021 -0500

    updated the file name for the notes on the broker data

commit 79ab5fc1a4d3cfa06338d36af979131cb528fb0e
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 14 09:28:05 2021 -0500

    renamed the file "notes_other_data_input.txt" to
    notes_self_generated_data.txt

commit b85e4c3d1c1cd123ec9a4eb397e3d2bb8dede595
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 7 12:25:36 2021 -0500

    minor modification to the notes on the data

commit 9804301fb542e15fac4d880e923d575264be8a3a
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 7 11:13:32 2021 -0500

    minor edit to the file to remove the numbering

commit 4d7c60d39a35ee94e528abc65fd7e3ed0add88e9
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 7 11:08:16 2021 -0500

    renamed a file and added a new file that discusses the underlying data

commit 90b8334e800dadf47915bcdf2f87e0518a0faaaf
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 7 10:29:47 2021 -0500

    added a new file about the underlying data and solutions to clean
    the data

commit f629ee96dafae84b203430bcb906e39630905cfc
Author: Rashawn <arctitan78@gmail.com>
Date:   Tue Dec 7 10:13:39 2021 -0500

    removed duplicate README file

commit 4e940811e779b92308b3511b7983d43c2305cbb8
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Dec 6 15:51:07 2021 -0500

    Added the README.md file in markdown format.

commit bfcbb41ab61c717668ba68ec7e441f88402d58ba
Author: Rashawn <arctitan78@gmail.com>
Date:   Mon Dec 6 14:52:53 2021 -0500

    This is the first commit of the project.
    I uploaded the README and the file that describes the process.
